{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bitesize00001/health_equity_lasi/blob/main/2_(5_3)_model_analysis(Fig_1%3B_Sup_table_3%3B_METHOD_Prediction_Density_Analysis%3B_RESULT_Predictive_Performance_of_Machine_Learning_Models).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uphKROdaubVc"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nigCUKn8tcnt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# For data preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# For classification model\n",
        "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# For deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# For evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NAdT4W0tuxB"
      },
      "outputs": [],
      "source": [
        "# Set display options to show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD-OtePUrmPV"
      },
      "outputs": [],
      "source": [
        "# set the working directory\n",
        "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW3Jvu4lrmPW"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e40NwEZGrmPX"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"derived_df.csv\")\n",
        "\n",
        "# Drop the target variables of other papers\n",
        "target_vars = ['bmi_underweight', 'bmi_overweight', 'waist_circumference']\n",
        "######################################\n",
        "target_var = 'waist_circumference'\n",
        "######################################\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn5t5-FPrmPY"
      },
      "outputs": [],
      "source": [
        "category_col = [\n",
        "    'education',\n",
        "    'state',\n",
        "    'region',\n",
        "    'religion',\n",
        "    'MPCE',\n",
        "    'working_status',\n",
        "    'occupation',\n",
        "    'caste',\n",
        "    'water',\n",
        "    'alcohol',\n",
        "    'activity1',\n",
        "    'benefit'\n",
        "    ]\n",
        "\n",
        "# Convert Type\n",
        "for col in data.columns:\n",
        "  if col in category_col:\n",
        "    data[col] = data[col].astype('category')\n",
        "  else:\n",
        "    data[col] = data[col].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTImUx7qrmPZ"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImXPLjeYrmPa"
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics data\n",
        "descriptive_data = data.copy()\n",
        "# Drop the missing values\n",
        "descriptive_data = data.dropna()\n",
        "descriptive_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RqX7GAsrmPc"
      },
      "outputs": [],
      "source": [
        "used_data = data.copy()\n",
        "# Drop the missing values\n",
        "used_data = used_data.dropna()\n",
        "# Define X and y\n",
        "X = used_data.drop(target_vars, axis=1)\n",
        "y = used_data[target_var]\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJLVSg7ermPd"
      },
      "outputs": [],
      "source": [
        "groups = {\n",
        "        'Overall': slice(None),\n",
        "        'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
        "        'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
        "        'General': X['caste'] == 'General',\n",
        "        'Other Backward Class': X['caste'] == 'Other backward class',\n",
        "        'MPCE 1': X['MPCE'] == 'Lowest',\n",
        "        'MPCE 2': X['MPCE'] == 'Lower middle',\n",
        "        'MPCE 3': X['MPCE'] == 'Middle',\n",
        "        'MPCE 4': X['MPCE'] == 'Upper middle',\n",
        "        'MPCE 5': X['MPCE'] == 'Highest',\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7372OeXrmPe"
      },
      "outputs": [],
      "source": [
        "# Category encoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
        "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'working_status_Never worked', 'occupation_Currently no work', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
        "# X = X.drop(dummy_col, axis=1)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnojz20_ujia"
      },
      "outputs": [],
      "source": [
        "X = X.astype('float32')\n",
        "y = y.astype('float32')\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_sd = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X_sd, columns=X.columns, index=X.index)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8unpZxpJrmPf"
      },
      "source": [
        "# Descriptive Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WGgyDcKrmPg"
      },
      "outputs": [],
      "source": [
        "# Define categories and their subcategories\n",
        "categories = {\n",
        "    'age_group': ['45-55', '55-65', '65-75', '75-85', '85+'],\n",
        "    'gender': descriptive_data['gender'].unique(),\n",
        "    'state': descriptive_data['state'].unique(),\n",
        "    'education': descriptive_data['education'].unique(),\n",
        "    'caste': descriptive_data['caste'].unique(),\n",
        "    'region': descriptive_data['region'].unique(),\n",
        "    'MPCE': descriptive_data['MPCE'].unique(),\n",
        "}\n",
        "\n",
        "# Create a new column for age group\n",
        "bins = [45, 55, 65, 75, 85, 150]\n",
        "labels = ['45-55', '55-65', '65-75', '75-85', '85+']\n",
        "descriptive_data['age_group'] = pd.cut(descriptive_data['age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Generate the descriptive_data structure\n",
        "table = {\n",
        "    'Category': [],\n",
        "    'Subcategory': [],\n",
        "    'Group Size': [],\n",
        "    'Group Proportion': [],\n",
        "    'Overall Prediction': descriptive_data[target_var].sum(),\n",
        "    'Prediction': [],\n",
        "    'Prediction Proportion': []\n",
        "}\n",
        "for category, subcats in categories.items():\n",
        "    grouped = descriptive_data.groupby(category)\n",
        "    for subcat in subcats:\n",
        "        subdata = grouped.get_group(subcat)\n",
        "        table['Category'].append(category)\n",
        "        table['Subcategory'].append(subcat)\n",
        "        table['Group Size'].append(len(subdata))\n",
        "        table['Group Proportion'].append(len(subdata) / len(descriptive_data))\n",
        "        table['Prediction'].append(subdata[target_var].sum())\n",
        "        table['Prediction Proportion'].append(subdata[target_var].sum() / descriptive_data[target_var].sum())\n",
        "\n",
        "table = pd.DataFrame(table)\n",
        "table['Group Proportion'] = table['Group Proportion'].map('{:.2%}'.format)\n",
        "table['Prediction Proportion'] = table['Prediction Proportion'].map('{:.2%}'.format)\n",
        "# save the table\n",
        "table.to_csv(f'standardized\\\\{target_var}\\\\descriptive_table.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEajFd7rrmPg"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8DRB2f3rmPh"
      },
      "outputs": [],
      "source": [
        "# Function: Define the function to create the DNN model\n",
        "def create_dnn_model(dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
        "\n",
        "    # Compile the model with AUROC as a metric\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVJ0f9x1rmPh"
      },
      "outputs": [],
      "source": [
        "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
        "def create_fcn_model(dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
        "\n",
        "    # Compile the model with AUROC as a metric\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJTeoD35rmPh"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5dv4E6zrmPi"
      },
      "outputs": [],
      "source": [
        "#logistic regression\n",
        "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "#random forest\n",
        "model_rf = RandomForestClassifier(random_state=42)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "#XGBoost\n",
        "model_xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "#gradient boosting\n",
        "model_gb = GradientBoostingClassifier(random_state=42)\n",
        "model_gb.fit(X_train, y_train)\n",
        "\n",
        "#lightGBM\n",
        "model_lgbm = LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1)\n",
        "model_lgbm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqucFJ85rmPi"
      },
      "outputs": [],
      "source": [
        "#DNN\n",
        "model_dnn = create_dnn_model(X_train.shape[1])\n",
        "model_dnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
        "model_dnn.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwb4jlUU_B1k"
      },
      "outputs": [],
      "source": [
        "#FCN\n",
        "model_fcn = create_fcn_model(X_train.shape[1])\n",
        "model_fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
        "model_fcn.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpRRjA__rmPj"
      },
      "outputs": [],
      "source": [
        "final_models = {\n",
        "    'Logistic Regression': model_lr,\n",
        "    'Random Forest': model_rf,\n",
        "    'XGBoost': model_xgb,\n",
        "    'Gradient Boosting': model_gb,\n",
        "    'LightGBM': model_lgbm,\n",
        "    'DNN': model_dnn,\n",
        "    'FCN': model_fcn\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDBYWlqyzUoT"
      },
      "source": [
        "# ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyXdd99P1lj8"
      },
      "outputs": [],
      "source": [
        "# Plot ROC Curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for model_name, model in final_models.items():\n",
        "    if model_name in ['DNN', 'FCN']:\n",
        "        y_proba = model.predict(X_test).ravel()\n",
        "    else:\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {auc:.2f})\", linewidth=3)\n",
        "\n",
        "# plot the roc curve for the random model\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.title(f'ROC Curves', fontsize=26)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=22)\n",
        "plt.yticks(fontsize=22)\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(f\"standardized\\\\{target_var}\\\\fig\\\\roc_curves.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93HUDFJZrmPk"
      },
      "outputs": [],
      "source": [
        "# Plot ROC Curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for model_name, model in final_models.items():\n",
        "    if model_name in ['DNN', 'FCN']:\n",
        "        # y_proba = model.predict(X_test).ravel()\n",
        "        continue\n",
        "    else:\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {auc:.2f})\", linewidth=3)\n",
        "\n",
        "# plot the roc curve for the random model\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.title(f'ROC Curves', fontsize=26)\n",
        "plt.legend(fontsize=20)\n",
        "plt.xticks(fontsize=22)\n",
        "plt.yticks(fontsize=22)\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(f\"standardized\\\\{target_var}\\\\fig\\\\roc_curves_2.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUFmFpeArmPl"
      },
      "source": [
        "# Density Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaBBIgUzrmPl"
      },
      "outputs": [],
      "source": [
        "# Function: Plot the density prediction plot by group\n",
        "def density_prediction_plot_by_group(model, model_name, X_test, y_test, target_var, groups):\n",
        "    # Evaluate and Plot for Each Group\n",
        "    for group_name, group_indices in groups.items():\n",
        "        X_group = X_test[group_indices]\n",
        "        y_group = y_test[group_indices]\n",
        "\n",
        "        # Predict the probabilities\n",
        "        if model_name in ['DNN', 'FCN']:\n",
        "            y_pred_proba_group = model.predict(X_group).ravel()\n",
        "        else:\n",
        "            y_pred_proba_group = model.predict_proba(X_group)[:, 1]\n",
        "\n",
        "        # Get the risk scores\n",
        "        risk_scores = y_pred_proba_group\n",
        "        risk_scores_neg = risk_scores[y_group == 0]\n",
        "        risk_scores_pos = risk_scores[y_group == 1]\n",
        "\n",
        "        # Create DataFrames for plotting\n",
        "        df_neg = pd.DataFrame({\"Predicted Probability\": risk_scores_neg, \"Label\": f\"Missing {target_var}\"})\n",
        "        df_pos = pd.DataFrame({\"Predicted Probability\": risk_scores_pos, \"Label\": f\"Having {target_var}\"})\n",
        "\n",
        "        # Plot the density plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        ax = plt.gca()\n",
        "        ax.spines['top'].set_visible(False)  # Hide the top spine\n",
        "        ax.spines['right'].set_visible(False)  # Hide the right spine\n",
        "        sns.kdeplot(data=df_neg, x=\"Predicted Probability\", color='orange', fill=True, alpha=0.5)\n",
        "        sns.kdeplot(data=df_pos, x=\"Predicted Probability\", color='blue', fill=True, alpha=0.5)\n",
        "        plt.xlabel(\"Predicted Probability\", fontsize=22)\n",
        "        plt.ylabel(\"Density\", fontsize=22)\n",
        "        plt.xticks(fontsize=24)\n",
        "        plt.yticks(fontsize=24)\n",
        "\n",
        "        plt.title(f\"{model_name}: {group_name} Density Plot\", fontsize=24)\n",
        "        plt.tight_layout()\n",
        "        # Save the plot\n",
        "        plt.savefig(f'standardized\\\\{target_var}\\\\fig\\\\{model_name}_{group_name}.png', pad_inches=0.1, bbox_inches='tight')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvrAXicqrmPm"
      },
      "outputs": [],
      "source": [
        "# for model_name, model in final_models.items():\n",
        "#     density_prediction_plot_by_group(model, model_name, X_test, y_test, target_var, groups)\n",
        "density_prediction_plot_by_group(model = model_lgbm, model_name = 'LightGBM', X_test = X_test, y_test = y_test, target_var = target_var, groups = groups)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "lasi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}